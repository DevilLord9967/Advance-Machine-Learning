{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment you will be working with `1C` dataset from the final competition. You are asked to encode `item_id` in 4 different ways:\n",
    "\n",
    "    1) Via KFold scheme;  \n",
    "    2) Via Leave-one-out scheme;\n",
    "    3) Via smoothing scheme;\n",
    "    4) Via expanding mean scheme.\n",
    "\n",
    "**You will need to submit** the correlation coefficient between resulting encoding and target variable up to 4 decimal places.\n",
    "\n",
    "### General tips\n",
    "\n",
    "* Fill NANs in the encoding with `0.3343`.\n",
    "* Some encoding schemes depend on sorting order, so in order to avoid confusion, please use the following code snippet to construct the data frame. This snippet also implements mean encoding without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from grader import Grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date  date_block_num  shop_id  item_id  item_price  \\\n",
      "0        02.01.2013               0       59    22154      999.00   \n",
      "1        03.01.2013               0       25     2552      899.00   \n",
      "2        05.01.2013               0       25     2552      899.00   \n",
      "3        06.01.2013               0       25     2554     1709.05   \n",
      "4        15.01.2013               0       25     2555     1099.00   \n",
      "5        10.01.2013               0       25     2564      349.00   \n",
      "6        02.01.2013               0       25     2565      549.00   \n",
      "7        04.01.2013               0       25     2572      239.00   \n",
      "8        11.01.2013               0       25     2572      299.00   \n",
      "9        03.01.2013               0       25     2573      299.00   \n",
      "10       03.01.2013               0       25     2574      399.00   \n",
      "11       05.01.2013               0       25     2574      399.00   \n",
      "12       07.01.2013               0       25     2574      399.00   \n",
      "13       08.01.2013               0       25     2574      399.00   \n",
      "14       10.01.2013               0       25     2574      399.00   \n",
      "15       11.01.2013               0       25     2574      399.00   \n",
      "16       13.01.2013               0       25     2574      399.00   \n",
      "17       16.01.2013               0       25     2574      399.00   \n",
      "18       26.01.2013               0       25     2574      399.00   \n",
      "19       27.01.2013               0       25     2574      399.00   \n",
      "20       09.01.2013               0       25     2593      279.00   \n",
      "21       16.01.2013               0       25     2604      299.00   \n",
      "22       27.01.2013               0       25     2604      299.00   \n",
      "23       27.01.2013               0       25     2607      279.00   \n",
      "24       29.01.2013               0       25     2607      279.00   \n",
      "25       27.01.2013               0       25     2609     1699.00   \n",
      "26       06.01.2013               0       25     2548     1708.95   \n",
      "27       26.01.2013               0       25     2611      299.00   \n",
      "28       02.01.2013               0       25     2546      299.00   \n",
      "29       06.01.2013               0       25     2515     1649.00   \n",
      "...             ...             ...      ...      ...         ...   \n",
      "2935819  16.10.2015              33       25     7789     1799.00   \n",
      "2935820  22.10.2015              33       25     7790      799.00   \n",
      "2935821  22.10.2015              33       25     7791      899.50   \n",
      "2935822  17.10.2015              33       25     7632     2310.00   \n",
      "2935823  26.10.2015              33       25     7487      299.00   \n",
      "2935824  14.10.2015              33       25     7029      999.00   \n",
      "2935825  23.10.2015              33       25     7460      299.00   \n",
      "2935826  04.10.2015              33       25     7233      599.00   \n",
      "2935827  18.10.2015              33       25     7308      349.00   \n",
      "2935828  21.10.2015              33       25     7233      479.00   \n",
      "2935829  03.10.2015              33       25     7233      599.00   \n",
      "2935830  11.10.2015              33       25     7286      299.00   \n",
      "2935831  22.10.2015              33       25     7187      299.00   \n",
      "2935832  26.10.2015              33       25     7484      299.00   \n",
      "2935833  22.10.2015              33       25     7308      349.00   \n",
      "2935834  29.10.2015              33       25     7235      298.00   \n",
      "2935835  18.10.2015              33       25     7327      349.00   \n",
      "2935836  22.10.2015              33       25     7327      349.00   \n",
      "2935837  24.10.2015              33       25     7328      249.00   \n",
      "2935838  17.10.2015              33       25     7338      349.00   \n",
      "2935839  24.10.2015              33       25     7315      399.00   \n",
      "2935840  31.10.2015              33       25     7409      299.00   \n",
      "2935841  11.10.2015              33       25     7393      349.00   \n",
      "2935842  10.10.2015              33       25     7384      749.00   \n",
      "2935843  09.10.2015              33       25     7409      299.00   \n",
      "2935844  10.10.2015              33       25     7409      299.00   \n",
      "2935845  09.10.2015              33       25     7460      299.00   \n",
      "2935846  14.10.2015              33       25     7459      349.00   \n",
      "2935847  22.10.2015              33       25     7440      299.00   \n",
      "2935848  03.10.2015              33       25     7460      299.00   \n",
      "\n",
      "         item_cnt_day  \n",
      "0                 1.0  \n",
      "1                 1.0  \n",
      "2                -1.0  \n",
      "3                 1.0  \n",
      "4                 1.0  \n",
      "5                 1.0  \n",
      "6                 1.0  \n",
      "7                 1.0  \n",
      "8                 1.0  \n",
      "9                 3.0  \n",
      "10                2.0  \n",
      "11                1.0  \n",
      "12                1.0  \n",
      "13                2.0  \n",
      "14                1.0  \n",
      "15                2.0  \n",
      "16                1.0  \n",
      "17                1.0  \n",
      "18                1.0  \n",
      "19                1.0  \n",
      "20                1.0  \n",
      "21                1.0  \n",
      "22                1.0  \n",
      "23                1.0  \n",
      "24                1.0  \n",
      "25                1.0  \n",
      "26                1.0  \n",
      "27                1.0  \n",
      "28                1.0  \n",
      "29                1.0  \n",
      "...               ...  \n",
      "2935819           1.0  \n",
      "2935820           1.0  \n",
      "2935821           1.0  \n",
      "2935822           1.0  \n",
      "2935823           1.0  \n",
      "2935824           1.0  \n",
      "2935825           1.0  \n",
      "2935826           1.0  \n",
      "2935827           1.0  \n",
      "2935828           1.0  \n",
      "2935829           1.0  \n",
      "2935830           1.0  \n",
      "2935831           1.0  \n",
      "2935832           1.0  \n",
      "2935833           1.0  \n",
      "2935834           1.0  \n",
      "2935835           1.0  \n",
      "2935836           1.0  \n",
      "2935837           1.0  \n",
      "2935838           1.0  \n",
      "2935839           1.0  \n",
      "2935840           1.0  \n",
      "2935841           1.0  \n",
      "2935842           1.0  \n",
      "2935843           1.0  \n",
      "2935844           1.0  \n",
      "2935845           1.0  \n",
      "2935846           1.0  \n",
      "2935847           1.0  \n",
      "2935848           1.0  \n",
      "\n",
      "[2935849 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('../readonly/final_project_data/sales_train.csv.gz')\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the competition task is to make a monthly prediction, we need to aggregate the data to montly level before doing any encodings. The following code-cell serves just that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          shop_id  item_id  date_block_num  target\n",
      "139255          0       19               0     0.0\n",
      "141495          0       27               0     0.0\n",
      "144968          0       28               0     0.0\n",
      "142661          0       29               0     0.0\n",
      "138947          0       32               0     6.0\n",
      "138948          0       33               0     3.0\n",
      "138949          0       34               0     0.0\n",
      "139247          0       35               0     1.0\n",
      "142672          0       40               0     0.0\n",
      "142065          0       41               0     0.0\n",
      "139208          0       42               0     0.0\n",
      "142670          0       43               0     1.0\n",
      "139207          0       44               0     0.0\n",
      "138950          0       45               0     0.0\n",
      "143764          0       46               0     0.0\n",
      "141505          0       47               0     0.0\n",
      "139199          0       48               0     0.0\n",
      "138952          0       49               0     0.0\n",
      "139176          0       50               0     0.0\n",
      "138951          0       51               0     2.0\n",
      "139177          0       52               0     0.0\n",
      "139178          0       53               0     0.0\n",
      "139179          0       54               0     0.0\n",
      "143769          0       55               0     0.0\n",
      "142671          0       56               0     0.0\n",
      "144539          0       57               0     0.0\n",
      "139180          0       59               0     0.0\n",
      "138953          0       60               0     0.0\n",
      "144265          0       61               0     1.0\n",
      "141744          0       63               0     0.0\n",
      "...           ...      ...             ...     ...\n",
      "10772600       59    22020              33     0.0\n",
      "10770510       59    22050              33     0.0\n",
      "10769953       59    22051              33     0.0\n",
      "10769955       59    22058              33     0.0\n",
      "10768833       59    22059              33     0.0\n",
      "10769961       59    22060              33     0.0\n",
      "10770625       59    22071              33     0.0\n",
      "10769956       59    22072              33     0.0\n",
      "10771598       59    22076              33     0.0\n",
      "10767854       59    22087              33     6.0\n",
      "10768086       59    22088              33     2.0\n",
      "10768087       59    22091              33     1.0\n",
      "10768088       59    22092              33     0.0\n",
      "10767847       59    22100              33     1.0\n",
      "10769954       59    22101              33     0.0\n",
      "10767848       59    22102              33     1.0\n",
      "10767849       59    22104              33     0.0\n",
      "10768089       59    22105              33     0.0\n",
      "10770726       59    22106              33     0.0\n",
      "10772844       59    22111              33     0.0\n",
      "10771530       59    22118              33     0.0\n",
      "10768090       59    22139              33     0.0\n",
      "10769958       59    22145              33     0.0\n",
      "10769959       59    22154              33     0.0\n",
      "10769704       59    22158              33     0.0\n",
      "10768834       59    22162              33     0.0\n",
      "10769024       59    22163              33     0.0\n",
      "10769690       59    22164              33     0.0\n",
      "10771216       59    22166              33     0.0\n",
      "10770511       59    22167              33     0.0\n",
      "\n",
      "[10913850 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "\n",
    "#fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean encodings without regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we did the techinical work, we are ready to actually *mean encode* the desired `item_id` variable. \n",
    "\n",
    "Here are two ways to implement mean encoding features *without* any regularization. You can use this code as a starting point to implement regularized techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483038698862\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483038698862\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the printed value? It is the correlation coefficient between the target variable and your new encoded feature. You need to **compute correlation coefficient** between the encodings, that you will implement and **submit those to coursera**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KFold scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 41 sec of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it's your turn to write the code!** \n",
    "\n",
    "You may use 'Regularization' video as a reference for all further tasks.\n",
    "\n",
    "First, implement KFold scheme with five folds. Use KFold(5) from sklearn.model_selection. \n",
    "\n",
    "1. Split your data in 5 folds with `sklearn.model_selection.KFold` with `shuffle=False` argument.\n",
    "2. Iterate through folds: use all but the current fold to calculate mean target for each level `item_id`, and  fill the current fold.\n",
    "\n",
    "    *  See the **Method 1** from the example implementation. In particular learn what `map` and pd.Series.map functions do. They are pretty handy in many situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480361473315\n",
      "Current answer for task KFold_scheme is: 0.480361473315\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "from sklearn import model_selection\n",
    "\n",
    "skf = model_selection.KFold(5, shuffle=True, random_state=123)\n",
    "\n",
    "for tr_ind, val_ind in skf.split(all_data.iloc[:,0]):\n",
    "    X_tr, X_val = all_data.iloc[tr_ind], all_data.iloc[val_ind]\n",
    " \n",
    "    all_data.loc[all_data.index[val_ind], 'item_target_enc'] = X_val['item_id'].map(X_tr.groupby('item_id').target.mean())\n",
    "   \n",
    "    \n",
    "all_data.fillna(0.3343, inplace=True)\n",
    "\n",
    "# You will need to compute correlation like that\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('KFold_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Leave-one-out scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, implement leave-one-out scheme. Note that if you just simply set the number of folds to the number of samples and run the code from the **KFold scheme**, you will probably wait for a very long time. \n",
    "\n",
    "To implement a faster version, note, that to calculate mean target value using all the objects but one *given object*, you can:\n",
    "\n",
    "1. Calculate sum of the target values using all the objects.\n",
    "2. Then subtract the target of the *given object* and divide the resulting value by `n_objects - 1`. \n",
    "\n",
    "Note that you do not need to perform `1.` for every object. And `2.` can be implemented without any `for` loop.\n",
    "\n",
    "It is the most convenient to use `.transform` function as in **Method 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480384831129\n",
      "Current answer for task Leave-one-out_scheme is: 0.480384831129\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "leave_one_out_sum = all_data['item_id'].map(all_data.groupby('item_id').target.sum())\n",
    "leave_one_out_count = all_data['item_id'].map(all_data.groupby('item_id').target.count())\n",
    "\n",
    "all_data['item_target_enc'] = ((leave_one_out_sum - all_data['target']))/(leave_one_out_count-1)\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)                                                \n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Leave-one-out_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 4:03 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement smoothing scheme with $\\alpha = 100$. Use the formula from the first slide in the video and $0.3343$ as `globalmean`. Note that `nrows` is the number of objects that belong to a certain category (not the number of rows in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "all_data['item_target_mean'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "all_data['item_target_enc_grp'] = all_data['item_target_mean'] * all_data['itemcat_count'] + globalmean * alpha\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Smoothing_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Expanding mean scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained starting at 5:50 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, implement the *expanding mean* scheme. It is basically already implemented for you in the video, but you can challenge yourself and try to implement it yourself. You will need [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) and [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html) functions from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)\n",
    "grader.submit_tag('Expanding_mean_scheme', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate token on this programming assignment page. Note: Token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_EMAIL = # EMAIL HERE\n",
    "STUDENT_TOKEN = # TOKEN HERE\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
